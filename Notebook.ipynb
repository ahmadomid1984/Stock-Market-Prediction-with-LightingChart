{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Analysis on Stock Prices using Machine Learning and LightningChart Python\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "#### 1.1 What is the stock market and how does it operate?\n",
    "The stock market is a complex network of buyers and sellers trading shares, operating as one of the most pivotal components of a free-market economy. It functions on fluctuating prices of shares based on supply and demand dynamics, investor sentiment, and various economic indicators.\n",
    "\n",
    "#### 1.2 Why is it important for stock traders to attempt stock price prediction analyses?\n",
    "For stock traders, predicting price movements can mean the difference between significant gains and losses. This highlights the crucial role of stock price prediction using machine learning in Python.\n",
    "\n",
    "#### 1.3 How can machine learning help in stock prices prediction?\n",
    "Machine learning, capable of analyzing vast datasets and identifying patterns, has emerged as a powerful tool for stock price prediction. This project explores various models and methodologies used to forecast market trends.\n",
    "\n",
    "#### 1.4 LSTM Model for Predicting Stock Prices\n",
    "The Long Short-Term Memory (LSTM) network, a type of recurrent neural network (RNN), is well-suited for sequence prediction problems like stock price forecasting due to its ability to capture temporal dependencies.\n",
    "\n",
    "### 2. LightningChart Python\n",
    "\n",
    "#### 2.1 Overview of LightningChart Python\n",
    "LightningChart Python is a high-performance data visualization library designed for creating complex, interactive, and real-time charts, particularly useful in financial applications.\n",
    "\n",
    "#### 2.2 Features and Chart Types to be Used in the Project\n",
    "- **XY Chart**: For visualizing data in two dimensions with series types such as Line Series, Point Line Series, and Area Series.\n",
    "- **3D Chart**: For a more immersive and detailed view of data trends.\n",
    "- **Line Chart**: Used for visualizing changes in stock prices over time.\n",
    "- **Stacked Bar Chart and Grouped Bar Chart**: For comparing different components of stock data.\n",
    "\n",
    "#### 2.3 Performance Characteristics\n",
    "Key performance characteristics include real-time data updating, high refresh rates, and efficient data handling, essential for financial applications where data needs to be processed and visualized in real-time.\n",
    "\n",
    "### 3. Setting Up Python Environment\n",
    "\n",
    "#### 3.1 Installing Python and Necessary Libraries\n",
    "Install Python from the official website and use pip to install necessary libraries including LightningChart Python from PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightningcharts random numpy pandas scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightningchart as lc\n",
    "import random\n",
    "lc.set_license('my-license-key')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Overview of Libraries Used\n",
    "- **LightningChart**: Advanced data visualization.\n",
    "- **NumPy**: Numerical computation.\n",
    "- **Pandas**: Data manipulation and analysis.\n",
    "- **Scikit-learn**: Data mining and data analysis.\n",
    "- **Tensorflow**: Machine learning model development.\n",
    "\n",
    "#### 3.3 Setting Up the Development Environment\n",
    "Recommended IDEs include Jupyter Notebook, PyCharm, or Visual Studio Code.\n",
    "\n",
    "### 4. Loading and Processing Data\n",
    "\n",
    "#### 4.1 How to Load the Data Files\n",
    "Data can be sourced from financial databases like Yahoo Finance, Alpha Vantage, and Quandl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "df_googl = pd.read_csv('./Alphabet Inc - Class A (GOOGL).csv')\n",
    "df_googl.rename(columns={\"Date\":\"date\",\"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\"}, inplace=True)\n",
    "df_googl['date'] = pd.to_datetime(df_googl.date)\n",
    "df_googl.sort_values(by='date', inplace=True)\n",
    "specified_start_date = pd.to_datetime('2020-01-01')\n",
    "specified_end_date = pd.to_datetime('2024-05-14')\n",
    "filtered_df = df_googl[(df_googl['date'] >= specified_start_date) & (df_googl['date'] <= specified_end_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Handling and preprocessing the data\n",
    "Preprocessing involves cleaning the data, handling missing values, and transforming it for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize/scale the close values between 0 and 1\n",
    "close_stock_values = filtered_df['close'].values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "normalized_close_values = scaler.fit_transform(close_stock_values)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "training_size = int(len(normalized_close_values) * 0.65)\n",
    "test_size = len(normalized_close_values) - training_size\n",
    "train_data, test_data = normalized_close_values[0:training_size, :], normalized_close_values[training_size:len(normalized_close_values), :]\n",
    "\n",
    "# Function to create dataset matrix for time-series prediction\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "# Reshape the data for LSTM model\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Validation of the Study\n",
    "- **Training Data Metrics**: Include RÂ² Score, RMSE, MSE, and MAE to showcase model accuracy.\n",
    "- **Testing Data Metrics**: Evaluate model generalizability and accuracy.\n",
    "\n",
    "### 5. Visualizing Data with LightningChart\n",
    "\n",
    "#### 5.1 Introduction to LightningChart for Python\n",
    "A tool for creating highly interactive and customizable charts, suitable for financial data visualization.\n",
    "\n",
    "#### 5.2 Creating the charts\n",
    "Create various charts using LightningChart Python to visualize stock data effectively.\n",
    "\n",
    "#### 5.3 Customizing visualizations\n",
    "LightningChart offers extensive customization options, including adjusting colors, adding markers, or integrating real-time data updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 - 5s - 484ms/step - loss: 0.0847 - val_loss: 0.0087\n",
      "Epoch 2/100\n",
      "11/11 - 1s - 77ms/step - loss: 0.0198 - val_loss: 0.0195\n",
      "Epoch 3/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0119 - val_loss: 0.0067\n",
      "Epoch 4/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0066 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 6/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 7/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 8/100\n",
      "11/11 - 0s - 31ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 9/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 11/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 12/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 14/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 15/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 16/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 17/100\n",
      "11/11 - 0s - 22ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 18/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 19/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 20/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 21/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 22/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 23/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 24/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 25/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 26/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 27/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 28/100\n",
      "11/11 - 0s - 28ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 29/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 30/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 31/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 32/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 33/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 34/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 35/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 36/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 37/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 38/100\n",
      "11/11 - 0s - 28ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 39/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 41/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 42/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 43/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 44/100\n",
      "11/11 - 0s - 28ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 46/100\n",
      "11/11 - 0s - 28ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 47/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 48/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 49/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 51/100\n",
      "11/11 - 0s - 28ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 52/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 53/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 54/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 55/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 56/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 57/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 58/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 59/100\n",
      "11/11 - 0s - 29ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 60/100\n",
      "11/11 - 0s - 27ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 61/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 62/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 63/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 64/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 65/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 67/100\n",
      "11/11 - 0s - 30ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 68/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 70/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 71/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 72/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 74/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 75/100\n",
      "11/11 - 0s - 28ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 76/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 77/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 78/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 79/100\n",
      "11/11 - 0s - 31ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 80/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 81/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 82/100\n",
      "11/11 - 0s - 28ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 83/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 84/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "11/11 - 0s - 25ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 86/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 87/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 88/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 89/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 90/100\n",
      "11/11 - 0s - 24ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 91/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 92/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 93/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 94/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 95/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 97/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 98/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 99/100\n",
      "11/11 - 0s - 26ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 100/100\n",
      "11/11 - 0s - 23ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "----Training Data Metrics----\n",
      "Train RMSE:  3.8083368960427695\n",
      "Train MSE:  14.503429913760675\n",
      "Train MAE:  2.9763278599605174\n",
      "-------------------------------\n",
      "----Testing Data Metrics----\n",
      "Test RMSE:  4.934602597755456\n",
      "Test MSE:  24.350302797774894\n",
      "Test MAE:  3.955520531465691\n",
      "-------------------------------\n",
      "----R2 score for regression----\n",
      "Train R2 Score:  0.9799701371832064\n",
      "Test R2 Score:  0.9451263149323985\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:50098\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x207cdc3f380>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Jun/2024 15:18:10] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Build and train the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=100, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Make predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Invert predictions back to original scale\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_inv, train_predict))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_inv, test_predict))\n",
    "train_mse = mean_squared_error(y_train_inv, train_predict)\n",
    "test_mse = mean_squared_error(y_test_inv, test_predict)\n",
    "train_mae = mean_absolute_error(y_train_inv, train_predict)\n",
    "test_mae = mean_absolute_error(y_test_inv, test_predict)\n",
    "train_r2 = r2_score(y_train_inv, train_predict)\n",
    "test_r2 = r2_score(y_test_inv, test_predict)\n",
    "\n",
    "# Evaluating the Model\n",
    "# Making predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Inverting predictions back to original scale\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training data\n",
    "train_rmse = math.sqrt(mean_squared_error(y_train_inv, train_predict))\n",
    "train_mse = mean_squared_error(y_train_inv, train_predict)\n",
    "train_mae = mean_absolute_error(y_train_inv, train_predict)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for testing data\n",
    "test_rmse = math.sqrt(mean_squared_error(y_test_inv, test_predict))\n",
    "test_mse = mean_squared_error(y_test_inv, test_predict)\n",
    "test_mae = mean_absolute_error(y_test_inv, test_predict)\n",
    "\n",
    "# R2 score for regression\n",
    "train_r2 = r2_score(y_train_inv, train_predict)\n",
    "test_r2 = r2_score(y_test_inv, test_predict)\n",
    "\n",
    "# Print training and testing metrics\n",
    "print(\"----Training Data Metrics----\")\n",
    "print(\"Train RMSE: \", train_rmse)\n",
    "print(\"Train MSE: \", train_mse)\n",
    "print(\"Train MAE: \", train_mae)\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "print(\"----Testing Data Metrics----\")\n",
    "print(\"Test RMSE: \", test_rmse)\n",
    "print(\"Test MSE: \", test_mse)\n",
    "print(\"Test MAE: \", test_mae)\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "print(\"----R2 score for regression----\")\n",
    "print(\"Train R2 Score: \", train_r2)\n",
    "print(\"Test R2 Score: \", test_r2)\n",
    "\n",
    "\n",
    "# Predict next 10 days\n",
    "x_input = test_data[-time_step:].reshape(1, -1)\n",
    "temp_input = list(x_input)\n",
    "temp_input = temp_input[0].tolist()\n",
    "\n",
    "lst_output = []\n",
    "n_steps = time_step\n",
    "pred_days = 10\n",
    "\n",
    "for i in range(pred_days):\n",
    "    if len(temp_input) > time_step:\n",
    "        x_input = np.array(temp_input[1:])\n",
    "        x_input = x_input.reshape(1, -1)\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input = temp_input[1:]\n",
    "        lst_output.extend(yhat.tolist())\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        lst_output.extend(yhat.tolist())\n",
    "\n",
    "predicted_values = scaler.inverse_transform(np.array(lst_output).reshape(-1, 1))\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "future_dates = pd.date_range(start=filtered_df['date'].iloc[-1], periods=pred_days + 1, inclusive='right')\n",
    "prediction_df = pd.DataFrame({'date': future_dates, 'predicted_close': predicted_values.flatten()})\n",
    "\n",
    "# Prepare data for LC chart\n",
    "actual_dates = filtered_df['date'].tolist()\n",
    "actual_close = filtered_df['close'].tolist()\n",
    "predicted_dates = prediction_df['date'].tolist()\n",
    "predicted_close = prediction_df['predicted_close'].tolist()\n",
    "\n",
    "# Initialize LightningChart and set the license key\n",
    "chart = lc.ChartXY(title='Actual vs Predicted Close Prices')\n",
    "\n",
    "# Dispose the default x-axis and create a high precision datetime axis\n",
    "chart.get_default_x_axis().dispose()\n",
    "axis_x = chart.add_x_axis(axis_type='linear-highPrecision')\n",
    "axis_x.set_tick_strategy('DateTime')\n",
    "\n",
    "# Convert datetime to timestamps for plotting\n",
    "actual_date_timestamps = [x.timestamp() * 1000 for x in actual_dates]\n",
    "predicted_date_timestamps = [x.timestamp() * 1000 for x in predicted_dates]\n",
    "\n",
    "# Plot actual prices\n",
    "series_actual = chart.add_line_series()\n",
    "series_actual.add(x=actual_date_timestamps, y=actual_close)\n",
    "series_actual.set_name('Actual Prices')\n",
    "\n",
    "# Plot train predicted prices\n",
    "series_train_predicted = chart.add_line_series()\n",
    "series_train_predicted.add(x=actual_date_timestamps[:len(train_predict)], y=train_predict.flatten())\n",
    "series_train_predicted.set_name('Train Predictions')\n",
    "\n",
    "# Plot test predicted prices\n",
    "series_test_predicted = chart.add_line_series()\n",
    "series_test_predicted.add(x=actual_date_timestamps[len(train_predict):len(train_predict)+len(test_predict)], y=test_predict.flatten())\n",
    "series_test_predicted.set_name('Test Predictions')\n",
    "\n",
    "# Plot future predicted prices\n",
    "series_future_predicted = chart.add_line_series()\n",
    "series_future_predicted.add(x=predicted_date_timestamps, y=predicted_close)\n",
    "series_future_predicted.set_name('Future Predictions')\n",
    "\n",
    "# Add a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(series_actual)\n",
    "legend.add(series_train_predicted)\n",
    "legend.add(series_test_predicted)\n",
    "legend.add(series_future_predicted)\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some results' images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stacked Bar Chart](./images/Stacked%20Bar%20Chart.png)\n",
    "![Grouped Bar Chart](./images/Grouped%20Bar%20Chart.png)\n",
    "![Line Chart](./images/Line%20Chart.png)\n",
    "![Point Line Chart](./images/Point%20Line%20Chart.png)\n",
    "![Simple Line Chart](./images/Simple%20Line%20Chart.png)\n",
    "![Area Chart](./images/Area%20Chart.png)\n",
    "![3D Line Chart](./images/3D%20Line%20Chart.png)\n",
    "![Line Chart Comparison](./images/Line%20Chart%20Comparison.png)\n",
    "![Line Chart Prediction](./images/Line%20Chart%20Prediction.png)\n",
    "![Line Chart Prediction 2](./images/Line%20Chart%20Prediction%202.png)\n",
    "![Final Comparison and Prediction](./images/Final%20Comparison%20and%20Prediction.png)\n",
    "![Final Comparison and Prediction 2](./images/Final%20Comparison%20and%20Prediction%202.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "#### 6.1 Recap of creating the application and its usefulness\n",
    "This application demonstrates using advanced machine learning techniques and high-performance visualization tools to predict future stock prices, providing insightful and actionable information for stock traders.\n",
    "\n",
    "#### 6.2 Benefits of using LightningChart Python for visualizing data\n",
    "The library's performance and feature set make it an excellent choice for visualizing stock market data, ensuring traders have access to real-time data for timely and informed decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
